<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>College Attendance System (Client-Side) - Google Drive Ready (V2)</title>
    <!-- Load Tailwind CSS for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <style>
        /* Custom styles for a clean, mobile-first design */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f3f4f6;
        }
        .container-card {
            max-width: 95%;
            margin: 1rem auto;
            box-shadow: 0 10px 15px rgba(0, 0, 0, 0.1);
            border-radius: 12px;
            overflow: hidden;
        }
        #video, #overlay-canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #video-container {
            position: relative;
            width: 100%;
            /* Maintain an aspect ratio appropriate for webcams */
            padding-top: 75%; 
            height: 0; /* Use padding-top for responsive height */
            border-radius: 8px;
        }
        video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 8px;
            transform: scaleX(-1); /* Flip video horizontally for mirror view */
        }
        #overlay-canvas {
            transform: scaleX(-1); /* Flip canvas to match the flipped video */
        }
        .loading-message {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 1.25rem;
            color: #4b5563;
        }
    </style>
</head>
<body>

    <div class="container-card bg-white p-6 md:p-8">
        <h1 class="text-3xl font-bold text-gray-800 mb-2">Face Attendance Scanner</h1>
        <p class="text-gray-600 mb-6">Attendance check using **Google Drive** for reference images (supports multiple images per person).</p>

        <!-- Video Container -->
        <div id="video-container" class="mb-4 bg-gray-200 rounded-lg">
            <video id="video" autoplay muted></video>
            <canvas id="overlay-canvas"></canvas>
            <div id="loading" class="loading-message">Loading AI models...</div>
        </div>

        <!-- Status and Results Area -->
        <div id="status-message" class="p-4 text-center rounded-lg font-medium text-white shadow-md transition-all duration-300 bg-gray-500">
            System Initializing...
        </div>

        <!-- Instructions for Known Faces -->
        <div class="mt-6 p-4 bg-yellow-50 border border-yellow-200 rounded-lg">
            <h3 class="font-semibold text-lg text-yellow-800 mb-2">Known Faces List (Reference Data - Drive URLs)</h3>
            <p class="text-sm text-yellow-700">
                The system uses full Google Drive URLs. **IMPORTANT:** Each file must be set to "Public" sharing permission.
            </p>
            <ul id="known-faces-list" class="mt-2 text-sm text-yellow-900 list-disc list-inside grid grid-cols-2 sm:grid-cols-3">
                <!-- List will be populated by JS -->
            </ul>
        </div>

        <div id="error-message" class="mt-4 p-3 bg-red-100 text-red-700 rounded-lg hidden"></div>
    </div>
    
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@1.0.0/dist/face-api.min.js"></script>

    <script type="text/javascript">
        // Global Variables
        const video = document.getElementById('video');
        const canvas = document.getElementById('overlay-canvas');
        const statusMessage = document.getElementById('status-message');
        const knownFacesList = document.getElementById('known-faces-list');
        const errorMessage = document.getElementById('error-message');
        const MODEL_URL = './'; // <<< CHANGE APPLIED HERE: Looks for model files in the same folder
        const ATTENDANCE_THRESHOLD = 0.6; // Lower number is stricter match (0.6 is good balance)
        
        // --- START YOUR DATA DEFINITION HERE ---
        const knownPeople = [
            // REPLACE THESE PLACEHOLDER URLs WITH YOUR ACTUAL PUBLIC GOOGLE DRIVE LINKS
            // Multiple URLs are highly recommended for better accuracy!
            { label: 'Prashant Yadav', urls: [
                'https://drive.google.com/file/d/1DUC6JWodRRGTwDIPRbRdc14wzvJRfFnR/view?usp=drive_link',
                'https://drive.google.com/file/d/1sNolciYUKNSjIp5lkhL0abWnPQ_w2JqE/view?usp=drive_link'
            ] },
            { label: 'EM', urls: [
                'https://drive.google.com/file/d/1hlnuqIKUBu6lOVQFfYbUGtXeZyGqETo4/view?usp=drive_link'
            ]},
            // Placeholder data for 18 more students (Update with real data)
            { label: 'Student 3', urls: ['https://drive.google.com/file/d/PH_ID_3/view?usp=drive_link'] },
            { label: 'Student 4', urls: ['https://drive.google.com/file/d/PH_ID_4/view?usp=drive_link'] },
            { label: 'Student 5', urls: ['https://drive.google.com/file/d/PH_ID_5/view?usp=drive_link'] },
            { label: 'Student 6', urls: ['https://drive.google.com/file/d/PH_ID_6/view?usp=drive_link'] },
            { label: 'Student 7', urls: ['https://drive.google.com/file/d/PH_ID_7/view?usp=drive_link'] },
            { label: 'Student 8', urls: ['https://drive.google.com/file/d/PH_ID_8/view?usp=drive_link'] },
            { label: 'Student 9', urls: ['https://drive.google.com/file/d/PH_ID_9/view?usp=drive_link'] },
            { label: 'Student 10', urls: ['https://drive.google.com/file/d/PH_ID_10/view?usp=drive_link'] },
            { label: 'Student 11', urls: ['https://drive.google.com/file/d/PH_ID_11/view?usp=drive_link'] },
            { label: 'Student 12', urls: ['https://drive.google.com/file/d/PH_ID_12/view?usp=drive_link'] },
            { label: 'Student 13', urls: ['https://drive.google.com/file/d/PH_ID_13/view?usp=drive_link'] },
            { label: 'Student 14', urls: ['https://drive.google.com/file/d/PH_ID_14/view?usp=drive_link'] },
            { label: 'Student 15', urls: ['https://drive.google.com/file/d/PH_ID_15/view?usp=drive_link'] },
            { label: 'Student 16', urls: ['https://drive.google.com/file/d/PH_ID_16/view?usp=drive_link'] },
            { label: 'Student 17', urls: ['https://drive.google.com/file/d/PH_ID_17/view?usp=drive_link'] },
            { label: 'Student 18', urls: ['https://drive.google.com/file/d/PH_ID_18/view?usp=drive_link'] },
            { label: 'Student 19', urls: ['https://drive.google.com/file/d/PH_ID_19/view?usp=drive_link'] },
            { label: 'Student 20', urls: ['https://drive.google.com/file/d/PH_ID_20/view?usp=drive_link'] }
        ];
        // --- END YOUR DATA DEFINITION HERE ---

        let faceMatcher = null;
        let detectionInterval = null;

        /**
         * Extracts the File ID from the full Google Drive URL and converts it to a direct download URL.
         * @param {string} driveUrl - The full public Google Drive URL.
         * @returns {string|null} The direct public URL or null if parsing fails.
         */
        function getDriveDirectLink(driveUrl) {
            // Regex to match the file ID from a standard Google Drive sharing link
            const regex = /\/d\/([a-zA-Z0-9_-]+)/;
            const match = driveUrl.match(regex);
            
            if (match && match[1]) {
                const driveId = match[1];
                // This is the direct download format required for fetching image data
                return `https://drive.google.com/uc?export=download&id=${driveId}`;
            }
            console.warn("Failed to parse File ID from URL:", driveUrl);
            return null;
        }

        /**
         * Utility to display errors on the UI
         * @param {string} msg 
         */
        function displayError(msg) {
            errorMessage.textContent = `Error: ${msg}`;
            errorMessage.classList.remove('hidden');
            console.error(msg);
        }

        /**
         * 1. Loads all necessary AI models.
         * 2. Fetches and processes known face images to create descriptors.
         */
        async function loadModelsAndData() {
            try {
                statusMessage.textContent = 'Loading AI models...';
                
                // 1. Load models from the current folder (./)
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
                    faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
                    faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL)
                ]);

                statusMessage.textContent = 'Models loaded. Processing known faces from Google Drive...';

                // 2. Process known faces
                faceMatcher = await createFaceMatcher(knownPeople);

                document.getElementById('loading').style.display = 'none';
                statusMessage.textContent = 'Initialization Complete. Starting Webcam.';
                statusMessage.className = 'p-4 text-center rounded-lg font-bold text-white shadow-md transition-all duration-300 bg-green-500';

            } catch (error) {
                // This error usually happens if models are not found at the specified path (404 error)
                displayError('Failed during initialization. Check console for details (Model loading or Face processing failed).');
                console.error("Initialization Error:", error);
                document.getElementById('loading').textContent = 'Initialization Failed.';
            }
        }

        /**
         * Loads images via Google Drive links, detects faces, computes descriptors, and creates a FaceMatcher.
         * @param {Array<Object>} knownPeople - Array of objects with label and urls.
         * @returns {faceapi.FaceMatcher}
         */
        async function createFaceMatcher(knownPeople) {
            const labeledDescriptors = [];
            let successfulDescriptors = 0;

            for (const person of knownPeople) {
                const descriptors = [];
                // Display the name of the person being processed
                knownFacesList.innerHTML += `<li class="truncate">${person.label} (${person.urls.length} images)</li>`;

                for (const url of person.urls) {
                    const directLink = getDriveDirectLink(url);
                    if (!directLink) continue; // Skip if URL parsing failed

                    try {
                        // Fetch the image from the direct Google Drive link
                        const img = await faceapi.fetchImage(directLink);
                        
                        // Detect and compute descriptor for the image
                        const detection = await faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptor();

                        if (detection && detection.descriptor) {
                            descriptors.push(detection.descriptor);
                            successfulDescriptors++;
                        } else {
                            console.warn(`Could not detect face in image for ${person.label} from URL: ${url}. Skipping.`);
                        }
                    } catch (e) {
                        console.error(`Failed to fetch/process image for ${person.label} from URL: ${url}. Check "Public" permission.`, e);
                    }
                }

                // Only add a LabeledFaceDescriptors if at least one image had a successful face descriptor
                if (descriptors.length > 0) {
                    labeledDescriptors.push(
                        new faceapi.LabeledFaceDescriptors(person.label, descriptors)
                    );
                } else {
                    console.warn(`No valid face descriptors generated for ${person.label}. This person will be 'unknown'.`);
                }
            }

            if (labeledDescriptors.length === 0) {
                 throw new Error("Initialization Failed: No valid face descriptors could be generated from any provided images. Check all Google Drive URLs and file permissions.");
            }

            // Create the FaceMatcher with the generated descriptors and the threshold
            return new faceapi.FaceMatcher(labeledDescriptors, ATTENDANCE_THRESHOLD);
        }

        /**
         * Starts the webcam feed.
         */
        function startWebcam() {
            if (!faceMatcher) {
                return;
            }
            
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    video.srcObject = stream;
                    video.onloadedmetadata = () => {
                        // Once metadata is loaded, set the canvas to match the video dimensions
                        const displaySize = { width: video.clientWidth, height: video.clientHeight };
                        faceapi.matchDimensions(canvas, displaySize);

                        video.play();
                        
                        // Start the detection loop every 100ms (10 FPS)
                        detectionInterval = setInterval(() => detectAndRecognize(displaySize), 100);
                    };
                })
                .catch(err => {
                    displayError('Camera access failed. Please ensure you allow camera access and refresh the page. Details: ' + err.message);
                });
        }

        /**
         * Main loop for detection and recognition
         * @param {Object} displaySize - { width, height } of the video element
         */
        async function detectAndRecognize(displaySize) {
            if (video.paused || video.ended) {
                return;
            }

            // Detect faces, landmarks, and compute descriptors in one go
            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                .withFaceLandmarks()
                .withFaceDescriptors();

            // Resize detected boxes to fit the canvas display size
            const resizedDetections = faceapi.resizeResults(detections, displaySize);
            
            // Clear canvas from previous frame
            const context = canvas.getContext('2d');
            context.clearRect(0, 0, canvas.width, canvas.height);

            if (resizedDetections.length > 0) {
                resizedDetections.forEach(detection => {
                    // Find the best match for the face descriptor
                    const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
                    
                    let resultText = bestMatch.label;
                    let color = '#ff0000'; // Default to red (Unknown)
                    let statusClass = 'bg-red-500';

                    if (bestMatch.label !== 'unknown') {
                        // Display confidence for known faces
                        resultText = `${bestMatch.label} (${(1 - bestMatch.distance).toFixed(2)})`;
                        color = '#10b981'; // Emerald Green for known match
                        statusClass = 'bg-green-600';

                        statusMessage.textContent = `âœ… ATTENDANCE MARKED: ${bestMatch.label}`;
                        statusMessage.className = `p-4 text-center rounded-lg font-bold text-white shadow-lg ${statusClass}`;
                        
                        // *** REAL PROJECT STEP: You would save the name and timestamp to Firestore here ***
                        // Example: recordAttendance(bestMatch.label);
                    } else {
                        resultText = `Unknown (${bestMatch.distance.toFixed(2)})`;
                        statusMessage.textContent = 'Searching for face... Unknown Person Detected.';
                        statusMessage.className = 'p-4 text-center rounded-lg font-medium text-white shadow-md transition-all duration-300 bg-yellow-500';
                    }

                    // Draw the bounding box and label on the canvas
                    const box = detection.detection.box;
                    const drawBox = new faceapi.draw.DrawBox(box, { 
                        label: resultText,
                        boxColor: color,
                        lineWidth: 3,
                        fontSize: 18
                    });
                    drawBox.draw(canvas);
                });
            } else {
                 statusMessage.textContent = 'No face detected. Please center your face.';
                 statusMessage.className = 'p-4 text-center rounded-lg font-medium text-white shadow-md transition-all duration-300 bg-gray-500';
            }
        }

        // --- Execution Flow ---
        window.onload = async () => {
            // Check if faceapi loaded successfully before proceeding
            if (typeof faceapi === 'undefined') {
                displayError("Failed to load the face recognition library (face-api.js). Please check the CDN link or your network connection.");
                return; // Stop execution
            }

            // Load models and then start the webcam
            await loadModelsAndData();
            startWebcam();
        };

        // Handle resizing (important for responsive canvas)
        window.addEventListener('resize', () => {
            if (video.readyState === video.HAVE_METADATA) {
                 const displaySize = { width: video.clientWidth, height: video.clientHeight };
                 faceapi.matchDimensions(canvas, displaySize);
            }
        });

    </script>
</body>
</html>